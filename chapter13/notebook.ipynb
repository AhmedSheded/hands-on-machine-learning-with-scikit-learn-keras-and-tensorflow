{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-17T12:09:19.986741691Z",
     "start_time": "2023-08-17T12:09:11.667769493Z"
    },
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-17 15:09:12.639916: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-08-17 15:09:13.102919: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-08-17 15:09:16.935246: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9d2fafcfe638476",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-17T12:09:20.137961372Z",
     "start_time": "2023-08-17T12:09:20.075802064Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_TensorSliceDataset element_spec=TensorSpec(shape=(), dtype=tf.int32, name=None)>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = tf.range(10)\n",
    "dataset = tf.data.Dataset.from_tensor_slices(X)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c10c6ef4d88ceae9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-17T12:09:20.383612401Z",
     "start_time": "2023-08-17T12:09:20.123504287Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(1, shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "tf.Tensor(3, shape=(), dtype=int32)\n",
      "tf.Tensor(4, shape=(), dtype=int32)\n",
      "tf.Tensor(5, shape=(), dtype=int32)\n",
      "tf.Tensor(6, shape=(), dtype=int32)\n",
      "tf.Tensor(7, shape=(), dtype=int32)\n",
      "tf.Tensor(8, shape=(), dtype=int32)\n",
      "tf.Tensor(9, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "for item in dataset:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "182448c9e953a266",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-17T12:09:20.402124585Z",
     "start_time": "2023-08-17T12:09:20.231214741Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': (<tf.Tensor: shape=(), dtype=int32, numpy=1>, <tf.Tensor: shape=(), dtype=int32, numpy=4>), 'b': <tf.Tensor: shape=(), dtype=int32, numpy=7>}\n",
      "{'a': (<tf.Tensor: shape=(), dtype=int32, numpy=2>, <tf.Tensor: shape=(), dtype=int32, numpy=5>), 'b': <tf.Tensor: shape=(), dtype=int32, numpy=8>}\n",
      "{'a': (<tf.Tensor: shape=(), dtype=int32, numpy=3>, <tf.Tensor: shape=(), dtype=int32, numpy=6>), 'b': <tf.Tensor: shape=(), dtype=int32, numpy=9>}\n"
     ]
    }
   ],
   "source": [
    "X_nested = {\"a\": ([1, 2, 3], [4, 5, 6]),\n",
    "            \"b\": [7, 8, 9]}\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices(X_nested)\n",
    "for item in dataset:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9430dfeabd2d7988",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Chaining Transformations\n",
    "Once you have a dataset, you can apply all sorts of transformations to it by calling\n",
    "its transformation methods. Each method returns a new dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b705514b3a9151e0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-17T12:09:20.424013276Z",
     "start_time": "2023-08-17T12:09:20.260639389Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0 1 2 3 4 5 6], shape=(7,), dtype=int32)\n",
      "tf.Tensor([7 8 9 0 1 2 3], shape=(7,), dtype=int32)\n",
      "tf.Tensor([4 5 6 7 8 9 0], shape=(7,), dtype=int32)\n",
      "tf.Tensor([1 2 3 4 5 6 7], shape=(7,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices(tf.range(10))\n",
    "dataset = dataset.repeat(3).batch(7, drop_remainder=True)\n",
    "for item in dataset:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "acc227bc7b7dc8d7",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "You can also transform the items by calling the map() method. For example, this\n",
    "creates a new dataset with all batches multiplied by two:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84d9d92cebce7051",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-17T12:09:59.644789002Z",
     "start_time": "2023-08-17T12:09:59.540889788Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([ 0  2  4  6  8 10 12], shape=(7,), dtype=int32)\n",
      "tf.Tensor([14 16 18  0  2  4  6], shape=(7,), dtype=int32)\n",
      "tf.Tensor([ 8 10 12 14 16 18  0], shape=(7,), dtype=int32)\n",
      "tf.Tensor([ 2  4  6  8 10 12 14], shape=(7,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.map(lambda x : x*2) # x is a batch\n",
    "for item in dataset:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ec770c18159aba04",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "It is also possible to simply filter the dataset using the filter() method. For example,\n",
    "this code creates a dataset that only contains the batchs whose sum is greater than 50:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0af5f5a8412a310",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-17T12:14:09.665982209Z",
     "start_time": "2023-08-17T12:14:09.516411841Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([14 16 18  0  2  4  6], shape=(7,), dtype=int32)\n",
      "tf.Tensor([ 8 10 12 14 16 18  0], shape=(7,), dtype=int32)\n",
      "tf.Tensor([ 2  4  6  8 10 12 14], shape=(7,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.filter(lambda x: tf.reduce_sum(x)>50)\n",
    "for item in dataset:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2fe7a68a98f96fa6",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "You will often want to look at just a few items from a dataset. You can use the take()\n",
    "method for that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf1d931e86951f7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-17T12:15:31.178981107Z",
     "start_time": "2023-08-17T12:15:31.112228983Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([14 16 18  0  2  4  6], shape=(7,), dtype=int32)\n",
      "tf.Tensor([ 8 10 12 14 16 18  0], shape=(7,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "for item in dataset.take(2):\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f075658-8dfa-45b3-81f8-90855e7a7fdf",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Shuffling the Data\n",
    "\n",
    "You must specify the buffer size, and it is important\n",
    "to make it large enough, or else shuffling will not be very effective.1 Just donâ€™t exceed\n",
    "the amount of RAM you have, though even if you have plenty of it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fef36b95faaf02e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-17T12:23:14.514761571Z",
     "start_time": "2023-08-17T12:23:14.487433428Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0 1 2 5 4 7 9], shape=(7,), dtype=int64)\n",
      "tf.Tensor([0 8 1 3 4 6 3], shape=(7,), dtype=int64)\n",
      "tf.Tensor([6 8 7 9 2 5], shape=(6,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.range(10).repeat(2)\n",
    "dataset = dataset.shuffle(buffer_size=4, seed=222).batch(7)\n",
    "for item in dataset:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cc8771a5837bdef8",
   "metadata": {
    "collapsed": false
   },
   "source": [
    " If you call repeat() on a shuffled dataset, by default it will generate\n",
    "a new order at every iteration. This is generally a good idea, but if you prefer to reuse the same order at each iteration \n",
    "(e.g., for tests or debugging), you can set reshuffle_each_iteration=False when calling shuffle()."
   ]
  },
  {
   "cell_type": "raw",
   "id": "bc2ae8ded8f617ab",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "For a large dataset that does not fit in memory, this simple shuffling-buffer approach\n",
    "may not be sufficient, since the buffer will be small compared to the dataset. One\n",
    "solution is to shuffle the source data itself (for example, on Linux you can shuffle text\n",
    "files using the shuf command). This will definitely improve shuffling a lot! Even if\n",
    "the source data is shuffled, you will usually want to shuffle it some more, or else the\n",
    "same order will be repeated at each epoch, and the model may end up being biased\n",
    "(e.g., due to some spurious patterns present by chance in the source dataâ€™s order). To\n",
    "shuffle the instances some more, a common approach is to split the source data into\n",
    "multiple files, then read them in a random order during training. However, instances\n",
    "located in the same file will still end up close to each other. To avoid this you can pick\n",
    "multiple files randomly and read them simultaneously, interleaving their records.\n",
    "Then on top of that you can add a shuffling buffer using the shuffle() method. If\n",
    "this sounds like a lot of work, donâ€™t worry: the tf.data API makes all this possible in\n",
    "just a few lines of code. Letâ€™s go over how you can do this."
   ]
  },
  {
   "cell_type": "raw",
   "source": [
    "Interleaving Lines from Multiple Files\n",
    "First, suppose youâ€™ve loaded the California housing dataset, shuffled it (unless it was\n",
    "already shuffled), and split it into a training set, a validation set, and a test set. Then\n",
    "you split each set into many CSV files that each look like this (each row contains eight\n",
    "input features plus the target median house value):\n",
    "MedInc,HouseAge,AveRooms,AveBedrms,Populâ€¦,AveOccup,Latâ€¦,Longâ€¦,MedianHouseValue\n",
    "3.5214,15.0,3.050,1.107,1447.0,1.606,37.63,-122.43,1.442\n",
    "5.3275,5.0,6.490,0.991,3464.0,3.443,33.69,-117.39,1.687\n",
    "3.1,29.0,7.542,1.592,1328.0,2.251,38.44,-122.98,1.621\n",
    "[...]\n",
    "Letâ€™s also suppose train_filepaths contains the list of training filepaths (and you\n",
    "also have valid_filepaths and test_filepaths):\n",
    ">>> train_filepaths\n",
    "['datasets/housing/my_train_00.csv', 'datasets/housing/my_train_01.csv', ...]\n",
    "Alternatively, you could use file patterns; for example, train_filepaths =\n",
    "\"datasets/housing/my_train_*.csv\". Now letâ€™s create a dataset containing only\n",
    "these filepaths:\n",
    "filepath_dataset = tf.data.Dataset.list_files(train_filepaths, seed=42)By default, the list_files() function returns a dataset that shuffles the filepaths. In\n",
    "general this is a good thing, but you can set shuffle=False if you do not want that\n",
    "for some reason.\n",
    "Next, you can call the interleave() method to read from five files at a time and\n",
    "interleave their lines. You can also skip the first line of each fileâ€”which is the header\n",
    "rowâ€”using the skip() method):\n",
    "n_readers = 5\n",
    "dataset = filepath_dataset.interleave(\n",
    "    lambda filepath: tf.data.TextLineDataset(filepath).skip(1),\n",
    "    cycle_length=n_readers)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d9f51eccc69ae40"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "5ba362bb23ca78e6"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
